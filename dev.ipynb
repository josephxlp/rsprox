{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilspatches import *\n",
    "from upaths import tilenames, names_at_tilling_V1\n",
    "from upaths import TILES12_DPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_at_patching_V1 = ['edem_demw84','ldtm','pdem','tdem_dem',\n",
    "                        'egm08x','egm96x','s1x','s2x','tdem_hem','esawc','lwm',\n",
    "                       'tdem_dem_fw','tdem_dem_mw']\n",
    "\n",
    "len(names_at_patching_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# that code that start running from genvert foward or others foward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vrtvars = names_at_patching_V1\n",
    "i_wdir = TILES12_DPATH\n",
    "ps = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/media/ljp238/12TBWolf/RSPROX/TILES12_patches256/S01W063\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdirs = [os.path.join(path,i) for i in os.listdir(path)]\n",
    "subdirs = [i for i in subdirs if os.path.isdir(i)]\n",
    "for subdir in subdirs:\n",
    "    subdirs_tif = glob(os.path.join(subdir, '*.tif'))\n",
    "    print(f\"Number of .tif files in {subdir}: {len(subdirs_tif)}\")\n",
    "\n",
    "# make each subdirect column of df, and all the files as row, return a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from upaths import tilenames_full # tilenames_train  instead\n",
    "from upaths import PATCHE256_DPATH,CONFIG_PATCHE256_DPATH,columns_to_check\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def create_tif_dataframe(path):\n",
    "  subdirs = [os.path.join(path, i) for i in os.listdir(path)]\n",
    "  subdirs = [i for i in subdirs if os.path.isdir(i)]\n",
    "  data = {}\n",
    "  for subdir in subdirs:\n",
    "      subdirs_tif = glob(os.path.join(subdir, '*.tif'))\n",
    "      subdir_name = os.path.basename(subdir)\n",
    "      data[subdir_name] = subdirs_tif\n",
    "  df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in data.items()]))\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tilename in tilenames_full:\n",
    "    directory_path = os.path.join(PATCHE256_DPATH, tilename)\n",
    "    print(f\"Processing directory: {directory_path}\")\n",
    "    #csvpath = os.path.join(CONFIG_PATCHE256_DPATH, f'{tilename}_patches_count_null.csv')\n",
    "    #df = create_tif_dataframe(directory_path)\n",
    "    #print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "import rasterio\n",
    "\n",
    "from upaths import tilenames_full # tilenames_train  instead\n",
    "from upaths import PATCHE256_DPATH,CONFIG_PATCHE256_DPATH,columns_to_check\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# Assuming these are defined elsewhere in your code\n",
    "# from upaths import tilenames_full, PATCHE256_DPATH, CONFIG_PATCHE256_DPATH, columns_to_check\n",
    "\n",
    "def create_dataframe_from_directory(directory):\n",
    "  # Dictionary to hold lists of file paths for each subdirectory\n",
    "  data = {}\n",
    "\n",
    "  # Walk through the directory\n",
    "  for root, dirs, files in os.walk(directory):\n",
    "      # Get the relative path of the current directory\n",
    "      relative_path = os.path.relpath(root, directory)\n",
    "\n",
    "      # Skip the root directory itself\n",
    "      if relative_path == \".\":\n",
    "          continue\n",
    "\n",
    "      # Initialize a list for the current subdirectory if not already present\n",
    "      if relative_path not in data:\n",
    "          data[relative_path] = []\n",
    "\n",
    "      # Add full paths of .tif files to the list\n",
    "      for file in files:\n",
    "          if file.endswith('.tif'):\n",
    "              full_path = os.path.join(root, file)\n",
    "              data[relative_path].append(full_path)\n",
    "\n",
    "  # Create a DataFrame from the dictionary\n",
    "  if data:\n",
    "      df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in data.items()]))\n",
    "  else:\n",
    "      df = pd.DataFrame()\n",
    "\n",
    "  return df\n",
    "\n",
    "def count_nulls_in_rasters(df, columns):\n",
    "  # Add new columns for null counts\n",
    "  for column in columns:\n",
    "      if column in df.columns:\n",
    "          null_counts = []\n",
    "          for file_path in df[column].dropna():\n",
    "              try:\n",
    "                  with rasterio.open(file_path) as src:\n",
    "                      # Read the data\n",
    "                      data = src.read(1)\n",
    "                      # Count nulls (assuming nulls are represented by NaN or a specific nodata value)\n",
    "                      nodata_value = src.nodata\n",
    "                      if nodata_value is not None:\n",
    "                          null_count = (data == nodata_value).sum()\n",
    "                      else:\n",
    "                          null_count = pd.isnull(data).sum()\n",
    "                      null_counts.append(null_count)\n",
    "              except Exception as e:\n",
    "                  print(f\"Error processing file {file_path}: {e}\")\n",
    "                  null_counts.append(None)\n",
    "\n",
    "          # Add the null counts to the DataFrame\n",
    "          df[f'{column}_null_count'] = pd.Series(null_counts)\n",
    "\n",
    "  return df\n",
    "\n",
    "def count_nulls_by_variablelist(directory_path, columns_to_check, csvpath):\n",
    "  df = create_dataframe_from_directory(directory_path)\n",
    "  if df.empty:\n",
    "      print(f\"No .tif files found in {directory_path}\")\n",
    "  else:\n",
    "      print(df.head())\n",
    "      df_with_null_counts = count_nulls_in_rasters(df, columns_to_check)\n",
    "      df_with_null_counts.to_csv(csvpath, index=False)\n",
    "      print(f'Processed {directory_path} and saved to {csvpath}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  with ProcessPoolExecutor() as PEX:\n",
    "      for tilename in tilenames_full:\n",
    "          directory_path = os.path.join(PATCHE256_DPATH, tilename)\n",
    "          print(f\"Processing directory: {directory_path}\")\n",
    "          csvpath = os.path.join(CONFIG_PATCHE256_DPATH, f'{tilename}_patches_count_null.csv')\n",
    "\n",
    "          PEX.submit(count_nulls_by_variablelist, directory_path, columns_to_check, csvpath)\n",
    "        \n",
    "\n",
    "        \n",
    "       \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Count nulls and add new columns\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in getting DFRA # geotile has a way\n",
    "# water as 0, all other elevation filled \n",
    "# all features filled \n",
    "# there's no gaps in the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nodata  and print \n",
    "# all values in raster without nodata \n",
    "# filter any below or equall -99 and set to nodata \n",
    "# filter any above or equall to 10000 and set to nodata \n",
    "# remove old no value and replace it with a new one -9999. float \n",
    "# write the dataset\n",
    "# get nodata and print it \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from concurrent.futures import ThreadPoolExecutor #,ProcessPoolExecutor\n",
    "\n",
    "def create_dataframe_from_directory(directory):\n",
    "  # Dictionary to hold lists of file paths for each subdirectory\n",
    "  data = {}\n",
    "\n",
    "  # Walk through the directory\n",
    "  for root, dirs, files in os.walk(directory):\n",
    "      # Get the relative path of the current directory\n",
    "      relative_path = os.path.relpath(root, directory)\n",
    "\n",
    "      # Skip the root directory itself\n",
    "      if relative_path == \".\":\n",
    "          continue\n",
    "\n",
    "      # Initialize a list for the current subdirectory if not already present\n",
    "      if relative_path not in data:\n",
    "          data[relative_path] = []\n",
    "\n",
    "      # Add full paths of .tif files to the list\n",
    "      for file in files:\n",
    "          if file.endswith('.tif'):\n",
    "              full_path = os.path.join(root, file)\n",
    "              data[relative_path].append(full_path)\n",
    "\n",
    "  # Create a DataFrame from the dictionary\n",
    "  df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in data.items()]))\n",
    "\n",
    "  return df\n",
    "\n",
    "def count_nulls_in_file(file_path):\n",
    "  with rasterio.open(file_path) as src:\n",
    "      # Read the data\n",
    "      data = src.read(1)\n",
    "      # Count nulls (assuming nulls are represented by NaN or a specific nodata value)\n",
    "      nodata_value = src.nodata\n",
    "      if nodata_value is not None:\n",
    "          null_count = (data == nodata_value).sum()\n",
    "      else:\n",
    "          null_count = pd.isnull(data).sum()\n",
    "  return null_count\n",
    "\n",
    "def count_nulls_in_rasters(df, columns):\n",
    "  # Add new columns for null counts\n",
    "  for column in columns:\n",
    "      null_counts = []\n",
    "      file_paths = df[column].dropna().tolist()\n",
    "\n",
    "      # Use ThreadPoolExecutor for parallel processing\n",
    "      with ThreadPoolExecutor() as executor:\n",
    "          null_counts = list(executor.map(count_nulls_in_file, file_paths))\n",
    "\n",
    "      # Add the null counts to the DataFrame\n",
    "      df[f'{column}_null_count'] = pd.Series(null_counts)\n",
    "\n",
    "  return df\n",
    "\n",
    "# Example usage\n",
    "df = create_dataframe_from_directory(directory_path)\n",
    "\n",
    "# Specify the columns to check for nulls\n",
    "columns_to_check = ['ldtm', 'pdem', 'tdem_dem', 'tdem_dem_fw']\n",
    "columns_to_check_x =  [f'{col}_null_count' for col in columns_to_check]\n",
    "# Count nulls and add new columns\n",
    "df_with_null_counts = count_nulls_in_rasters(df, columns_to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pdem_null_count\n",
       "0        1088\n",
       "65536     108\n",
       "22272      34\n",
       "8960       32\n",
       "55040      32\n",
       "28187       1\n",
       "58607       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_null_counts[columns_to_check_x[1]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
